{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T_7lRLhiFOc",
        "outputId": "7a78c83d-a2b8-415c-9139-7d23a921f7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens: ['NLP', 'techniques', 'are', 'used', 'in', 'virtual', 'assistants', 'like', 'Alexa', 'and', 'Siri', '.']\n",
            "Tokens Without Stopwords: ['NLP', 'techniques', 'used', 'virtual', 'assistants', 'like', 'Alexa', 'Siri', '.']\n",
            "Stemmed Words: ['nlp', 'techniqu', 'use', 'virtual', 'assist', 'like', 'alexa', 'siri', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download required resources (only the first time)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') # 'punkt_tab' does not exist, using 'punkt' instead.\n",
        "\n",
        "def preprocess_text(sentence):\n",
        "    # 1. Tokenize the sentence\n",
        "    tokens = word_tokenize(sentence)\n",
        "    print(\"Original Tokens:\", tokens)\n",
        "\n",
        "    # 2. Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    print(\"Tokens Without Stopwords:\", filtered_tokens)\n",
        "\n",
        "    # 3. Apply stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "    print(\"Stemmed Words:\", stemmed_tokens)\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"NLP techniques are used in virtual assistants like Alexa and Siri.\"\n",
        "preprocess_text(sentence)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy's English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Input sentence\n",
        "sentence = \"Barack Obama served as the 44th President of the United States and won the Nobel Peace Prize in 2009.\"\n",
        "\n",
        "# Process the sentence with spaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Print named entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Text: {ent.text}, Label: {ent.label_}, Start: {ent.start_char}, End: {ent.end_char}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0skmXpblMqU",
        "outputId": "d4ac5b0b-1c7a-48b1-fc31-73a5373f7be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Barack Obama, Label: PERSON, Start: 0, End: 12\n",
            "Text: 44th, Label: ORDINAL, Start: 27, End: 31\n",
            "Text: the United States, Label: GPE, Start: 45, End: 62\n",
            "Text: the Nobel Peace Prize, Label: WORK_OF_ART, Start: 71, End: 92\n",
            "Text: 2009, Label: DATE, Start: 96, End: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # stability\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "def scaled_dot_product_attention(Q, K, V):\n",
        "    d_k = Q.shape[-1]  # Key dimension\n",
        "    # Step 1: Compute dot product between Q and Kᵀ\n",
        "    scores = np.dot(Q, K.T)\n",
        "\n",
        "    # Step 2: Scale by √d_k\n",
        "    scaled_scores = scores / np.sqrt(d_k)\n",
        "\n",
        "    # Step 3: Apply softmax\n",
        "    attention_weights = softmax(scaled_scores)\n",
        "\n",
        "    # Step 4: Multiply weights by V\n",
        "    output = np.dot(attention_weights, V)\n",
        "\n",
        "    return attention_weights, output\n",
        "\n",
        "# Test inputs\n",
        "Q = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
        "K = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
        "V = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "\n",
        "# Run the attention\n",
        "attention_weights, output = scaled_dot_product_attention(Q, K, V)\n",
        "\n",
        "# Display results\n",
        "print(\"Attention Weights:\\n\", attention_weights)\n",
        "print(\"Output:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dffs8GIOoARM",
        "outputId": "330e72b0-900a-45d5-d0fb-457c0b7ef12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights:\n",
            " [[0.73105858 0.26894142]\n",
            " [0.26894142 0.73105858]]\n",
            "Output:\n",
            " [[2.07576569 3.07576569 4.07576569 5.07576569]\n",
            " [3.92423431 4.92423431 5.92423431 6.92423431]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained sentiment analysis pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Input sentence\n",
        "text = \"Despite the high price, the performance of the new MacBook is outstanding.\"\n",
        "\n",
        "# Analyze sentiment\n",
        "result = classifier(text)[0]\n",
        "\n",
        "# Display result\n",
        "print(f\"Sentiment: {result['label']}\")\n",
        "print(f\"Confidence Score: {result['score']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391,
          "referenced_widgets": [
            "0212f103e3cc47639b9d3c1d1d411f4b",
            "4a9df814552748308c8f96e3f57e366d",
            "fc4ab2393d034fcda3a9bf64f106863c",
            "938c3bf0d4c5479581130b92d3d45cd9",
            "11608ad94dc2499092edffcae0d0c197",
            "ffdd39dd1c014af18e47f94dfd3a1441",
            "a28bbb4911224814a6f36fc4bc229677",
            "b0e31b95923849d2b243eec642f1c324",
            "d8a80cd250d84e8daad157d4fcd9cdad",
            "0e05fb0292e740129b4afc9471c2f6a4",
            "593d99ecf60e4b8b8d61c1cb16448a57",
            "b20cf98c9fc54d04b43c843a2fed288d",
            "78a7989a4a8d44edb3b0f255095b343d",
            "e2339ffa56ce4df3b31f5b41bc4bda2a",
            "eac46187f11344239d526f76794d78eb",
            "b983a764a1ce4f55ae0755e9a93a44e2",
            "2c288cdf994447f1acf225b75cab9ccf",
            "125b322157c14acf951c1a1bf5639dfa",
            "b4b78e551c3b4bd1bf860b0f16cc8f32",
            "2ca58e85254149158eb1e473e5d29a9d",
            "e638129628464014952a0df2bdc9f5ed",
            "5800e87cfcbd4863b6cbf4776bf1f91c",
            "64c87c21425347b2b45d7e2338a9d713",
            "d86f5608b4864179bd5766c02dac2c1e",
            "26e62ad64e5b4a8c92c5e54d66f38a6e",
            "796367ec214a445a9cd242a5078f4089",
            "d9e99e49996f47c09c627cb5730a4e5a",
            "90412702dbde4d0a8bc4805666d14780",
            "e25196632b8a4a6489747a2e4f182356",
            "598607aff1244d5398e5fe02a1b80334",
            "6b560a037e9b485ebedec334a6fa6560",
            "0fdc537f874d403491d2172e2e6c2a39",
            "47ef2e0e934646529d99397c4ff46f1f",
            "1a65abcb866942a7af7f9671d1965e37",
            "f38253f944ad45dea9c058651c2782bd",
            "bcb8569608f94f51bb9b414abb023afe",
            "bd821387de284937bc548a5e8899c6dc",
            "1d2880a90fd04442864826db643b0f7a",
            "d338dcbef10944d19d1b07d1f04e0961",
            "d759ecbd99b142a8901eed4059a7d658",
            "5874f86400624768aed22c15de37498f",
            "ed1c9bc681dc482580b50384268138de",
            "d26d2c9e03b74bbd91cfff59c613d3b1",
            "d70747d76de34b2caa265ed7c8666b5b"
          ]
        },
        "id": "iJYcONJnr8Kn",
        "outputId": "a554f631-8640-4edc-e6b4-f689213517ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0212f103e3cc47639b9d3c1d1d411f4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b20cf98c9fc54d04b43c843a2fed288d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64c87c21425347b2b45d7e2338a9d713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a65abcb866942a7af7f9671d1965e37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: POSITIVE\n",
            "Confidence Score: 0.9998\n"
          ]
        }
      ]
    }
  ]
}
